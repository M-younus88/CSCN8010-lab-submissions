{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SciKit-Learn, train a logistic regression model on the Iris dataset. Use all four features. Define only 2 labels: virginica and non-virginica. See the logistic regression notebook presented in class for a demonstration on how to set up these labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)   \n",
      "0                5.1               3.5                1.4               0.2  \\\n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Extract the features and target from the dataset\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a dataframe with the features\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Print the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Create binary labels: 'virginica' and 'non-virginica'\n",
    "y_binary = np.where(iris.target_names[y] == 'virginica', 'virginica', 'non-virginica')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide insights about the model prediction. This is an open-ended part. But you can look into questions such as in which data instances is the model wrong? are there any shared properties for these cases? and _how is the model doing, across a set of performance metrics such as accuracy and confusion metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may evaluate the model's performance across many data instances, pinpoint instances in which it fails to make accurate predictions, and look for any common traits between these instances to learn more about the model's predictions. A more thorough knowledge of the model's performance can also be obtained by measuring its performance using measures like accuracy and a confusion matrix. Here are some things to think about:\n",
    "\n",
    "Inaccurate predictions: We can spot situations when the model is off by comparing the predicted labels with the actual labels. For instance, we can look at instances where the model incorrectly labels a sample as virginica or non-virginica. By scrutinising these occurrences, we can search for trends or common traits that might be the model's fault.\n",
    "\n",
    "Shared characteristics of examples that were incorrectly classified: By examining any common characteristics among the incorrectly classified instances, we can learn why the model is inaccurate. This can entail looking at the correlations between the misclassifications and feature values like sepal length, sepal width, petal length, and petal width. Are there particular feature value ranges or combinations that frequently result in incorrect classifications? Investigating these patterns can provide information about the model's shortcomings or regions of the dataset that can be difficult to adequately segregate.\n",
    "\n",
    "Metrics for measuring performance: A quantitative evaluation of the model's predictive skills can be obtained by measuring the model's performance using metrics like accuracy and a confusion matrix. The percentage of instances that are correctly classified out of all instances is known as accuracy. The model's predictions are broken out in great depth in the confusion matrix, which displays the proportion of true positives, true negatives, erroneous positives, and false negatives. We can derive metrics like precision, recall, and F1-score from the confusion matrix, which provide a more detailed picture of the model's performance for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[19  0]\n",
      " [ 0 11]]\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred, pos_label='virginica')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, pos_label='virginica')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred, pos_label='virginica')\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the performance measures and model prediction:\n",
    "\n",
    "Accuracy: On the test set, the logistic regression model had an accuracy of 1.0, meaning that all predictions were accurate. It's crucial to remember that this high accuracy could be impacted by the dataset's class imbalance or overfitting.\n",
    "\n",
    "Accuracy of Cross-Validation: The model's accuracy varied for each split when cross-validation was conducted with 5 splits. It was discovered that the mean accuracy across the splits was 94.6%, providing a more accurate assessment of the model's performance.\n",
    "\n",
    "Confusion Matrix: According to the confusion matrix, neither false positive nor false negative predictions were made by the model on the test set. Cross-validated predictions, however, revealed one false negative prediction, indicating that the model misclassified one occurrence of virginica as non-virginica.\n",
    "\n",
    "Precision: The logistic regression model's precision score was 1.0, meaning that all instances of positive prediction were accurate. Cross-validation, however, revealed that the precision scores varied between the splits and had a mean precision of 0.95.\n",
    "\n",
    "Recall: The logistic regression model's recall score was 1.0, meaning that all instances of true positives were correctly predicted. The mean recall, however, was 0.948 when cross-validated recall scores were taken into account, demonstrating some heterogeneity between the divides.\n",
    "\n",
    "Overall, the logistic regression model performed well and showed high accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
