{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practical Lab-5 Dwarakanath Chandra (8856840)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-1**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Utilize the diabetes dataset from lab 4. Perform cross-validation on nine polynomial models, ranging from degree 0 to 8.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries and packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from typing import List\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Diabetes dataset\n",
    "\n",
    "X, y = datasets.load_diabetes(as_frame=True, scaled=False, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a polynomial model creation function with varying degrees\n",
    "\n",
    "def create_polynomial_models(X: np.ndarray, y: np.ndarray, degrees: List[int]) -> dict[int, np.poly1d]:\n",
    "    \"\"\"\n",
    "    Creates polynomial models for the given degrees and fits them to the given data.\n",
    "\n",
    "    Args\n",
    "        X: The x values of the data.\n",
    "        y: The y values of the data.\n",
    "        degrees: A list of polynomial degrees to try.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of polynomial models, with the polynomial degree as the key.\n",
    "    \"\"\"\n",
    "\n",
    "    models = {}\n",
    "    for degree in degrees:\n",
    "        model = Pipeline([('polynomial', PolynomialFeatures(degree=degree)),\n",
    "                          ('linear', LinearRegression())])\n",
    "        model.fit(X, y)\n",
    "        models[degree] = model\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=0)),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 1: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=1)),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 2: Pipeline(steps=[('polynomial', PolynomialFeatures()),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 3: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=3)),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 4: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=4)),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 5: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=5)),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 6: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=6)),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 7: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=7)),\n",
       "                 ('linear', LinearRegression())]),\n",
       " 8: Pipeline(steps=[('polynomial', PolynomialFeatures(degree=8)),\n",
       "                 ('linear', LinearRegression())])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Polynomial Models ranging degree from 0 to 8\n",
    "\n",
    "degrees = list(range(0, 9))\n",
    "\n",
    "models = create_polynomial_models(X, y, degrees)\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pipeline_model_stats(model):\n",
    "    # print model    \n",
    "    print(f'Model: {model}')\n",
    "    \n",
    "    if isinstance(model[-1].coef_, (list, np.ndarray)):\n",
    "        if len(model[-1].coef_) > 0:\n",
    "            if isinstance(model[-1].coef_[0], (list, np.ndarray)):\n",
    "                print(f'Coefficients: {model[-1].coef_[0][1:]}')\n",
    "            else:\n",
    "                print(f'Coefficients: {model[-1].coef_[1:]}')\n",
    "        else:\n",
    "            print('No coefficients found.')\n",
    "    else:\n",
    "        print(f'Coefficients: {model[-1].coef_}')\n",
    "    \n",
    "    if isinstance(model[-1].intercept_, (list, np.ndarray)):\n",
    "        if len(model[-1].intercept_) > 0:\n",
    "            intercept = model[-1].intercept_[0]\n",
    "            print(f'Intercept: {intercept}')\n",
    "        else:\n",
    "            print('No intercept found.')\n",
    "    else:\n",
    "        intercept = model[-1].intercept_\n",
    "        print(f'Intercept: {intercept}')\n",
    "    \n",
    "    # generate equation string:\n",
    "    if isinstance(intercept, (int, float)):\n",
    "        equation = f\"y = {intercept:.2f}\"\n",
    "    else:\n",
    "        equation = \"y = \"\n",
    "    \n",
    "    if isinstance(model[-1].coef_, (list, np.ndarray)):\n",
    "        if len(model[-1].coef_) > 0:\n",
    "            if isinstance(model[-1].coef_[0], (list, np.ndarray)):\n",
    "                coefficients = model[-1].coef_[0][1:]\n",
    "            else:\n",
    "                coefficients = model[-1].coef_[1:]\n",
    "            \n",
    "            for ind, coeff in enumerate(coefficients):\n",
    "                degree = ind + 1\n",
    "                equation += f\" + {coeff:.2f}x^{degree}\"\n",
    "    print(f'Equation: {equation}')\n",
    "    print('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print models and their coefficients\n",
    "\n",
    "#for degree, model in models.items():\n",
    "    #print_pipeline_model_stats(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-2**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construct a table summarizing the cross-validation results. Each model should have a separate row in the table. Include the R-Squared and Mean Absolute Error (MAE) metrics for each model. Calculate the mean value and standard deviation of these metrics from the cross-validation. Include both values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree              R-Squared                MAE R-Squared_mean R-Squared_std MAE_mean MAE_std\n",
      "     0         -0.028 ± 0.037     66.046 ± 3.475         -0.028         0.037   66.046   3.475\n",
      "     1          0.482 ± 0.049     44.276 ± 2.100          0.482         0.049   44.276   2.100\n",
      "     2         -1.485 ± 1.618    80.595 ± 24.657         -1.485         1.618   80.595  24.657\n",
      "     3     -203.419 ± 225.878  342.052 ± 142.438       -203.419       225.878  342.052 142.438\n",
      "     4     -571.083 ± 369.892  657.260 ± 159.476       -571.083       369.892  657.260 159.476\n",
      "     5     -436.857 ± 379.100   562.994 ± 59.917       -436.857       379.100  562.994  59.917\n",
      "     6   -1694.550 ± 2629.990  742.717 ± 190.709      -1694.550      2629.990  742.717 190.709\n",
      "     7   -5530.894 ± 9518.587 1032.682 ± 393.440      -5530.894      9518.587 1032.682 393.440\n",
      "     8 -16076.255 ± 28049.953 1475.659 ± 706.280     -16076.255     28049.953 1475.659 706.280\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Degree', 'R-Squared', 'MAE'])\n",
    "\n",
    "for degree, model in models.items():\n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validate(model, X, y, cv=5, scoring=['r2', 'neg_mean_absolute_error'])\n",
    "    \n",
    "    # Calculate mean and standard deviation of the metrics\n",
    "    r2_mean = np.mean(cv_results['test_r2'])\n",
    "    r2_std = np.std(cv_results['test_r2'])\n",
    "    mae_mean = -np.mean(cv_results['test_neg_mean_absolute_error'])\n",
    "    mae_std = np.std(cv_results['test_neg_mean_absolute_error'])\n",
    "    \n",
    "    # Add the results to the DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        'Degree': [degree],\n",
    "        'R-Squared': [f\"{r2_mean:.3f} ± {r2_std:.3f}\"],\n",
    "        'R-Squared_mean': [f\"{r2_mean:.3f}\"],\n",
    "        'R-Squared_std': [f\"{r2_std:.3f}\"],\n",
    "        'MAE': [f\"{mae_mean:.3f} ± {mae_std:.3f}\"],\n",
    "        'MAE_mean':[f\"{mae_mean:.3f}\"],\n",
    "        'MAE_std':[f\"{mae_std:.3f}\"]\n",
    "    })\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Converting results dataframe to a table\n",
    "results_table = results.to_string(index=False)\n",
    "\n",
    "# Print the table\n",
    "print(results_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question-3**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Identification of the Best Model: Identify the model that exhibits the highest performance based on the R-Squared and MAE metrics. Provide an explanation for choosing this specific model.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Currently, there are 9 models of varying polynomial degrees ranging from 0 to 8. To identify the best model among the 9 models, we have already performed the cross-validation based on scores of R_Squared and Negative Mean Absolute Error (MAE) and claculated the mean and standard deviation for these performance metrics as shown above.**\n",
    "\n",
    "##### **In order to select the best model among the 9 polynomial models, we need to identify the model of certain degree with higher R_Squared value and lower MAE value compared to other models. The higher the R_Squared value, the greater the amount of variation in data explained. The lower the MAE value, the smaller the deviation between predicted value and actual values of the models.**\n",
    "\n",
    "##### **Hence, the objective of finding the best model is to explore a model of certain degree with higher R_Squared and lower MAE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree                         1\n",
      "R-Squared          0.482 ± 0.049\n",
      "MAE               44.276 ± 2.100\n",
      "R-Squared_mean             0.482\n",
      "R-Squared_std              0.049\n",
      "MAE_mean                  44.276\n",
      "MAE_std                    2.100\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sort the results DataFrame by R-Squared in descending order and MAE in ascending order\n",
    "sorted_results = results.sort_values(by=['R-Squared', 'MAE'], ascending=[False, True])\n",
    "\n",
    "# Get the best model (first row in the sorted DataFrame)\n",
    "best_model = sorted_results.iloc[0]\n",
    "\n",
    "# Print the best model\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model based on R-squared: Degree 1\n",
      "Best model based on MAE: Degree 1\n",
      "  Degree  R-Squared     MAE R-Squared_mean R-Squared_std MAE_mean MAE_std\n",
      "1      1      0.482  44.276          0.482         0.049   44.276   2.100\n"
     ]
    }
   ],
   "source": [
    "# Update the code to handle the 'R-Squared' and 'MAE' columns correctly\n",
    "results['R-Squared'] = results['R-Squared'].apply(lambda x: float(x.split(' ±')[0]) if isinstance(x, str) else x)\n",
    "results['MAE'] = results['MAE'].apply(lambda x: float(x.split(' ±')[0]) if isinstance(x, str) else x)\n",
    "\n",
    "# Find the index of the model with the highest R-squared\n",
    "best_r2_index = results['R-Squared'].idxmax()\n",
    "\n",
    "# Find the index of the model with the lowest MAE\n",
    "best_mae_index = results['MAE'].idxmin()\n",
    "\n",
    "# Get the degree of the model with the highest R-squared\n",
    "best_r2_degree = results.loc[best_r2_index, 'Degree']\n",
    "\n",
    "# Get the degree of the model with the lowest MAE\n",
    "best_mae_degree = results.loc[best_mae_index, 'Degree']\n",
    "\n",
    "# Print the best models based on R-squared and MAE\n",
    "print(\"Best model based on R-squared: Degree\", best_r2_degree)\n",
    "print(\"Best model based on MAE: Degree\", best_mae_degree)\n",
    "print(results[results[\"Degree\"]==1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Hence, the selected best model is the linear model of degree-1 with 10 features because, it has high R_Squared value (0.482) and lower MAE value (44.276) compared to all other polynomial models.**\n",
    "\n",
    "##### **Though R_Squared value of 0.482 indicates average prediction performance, that is the best among all among polynomial models. AS the degree of polynomial models increasing, the model performance is dropping significantly due to the overfitting and noise due to introduction of interaction terms**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
